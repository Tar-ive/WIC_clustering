{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1Yn5pJmXiWeZjPTEEm+JB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tar-ive/WIC_clustering/blob/main/wic_data_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhzXD_kNjPJJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('RTPH_Survey_stand_TLL_4.1.25.csv')\n",
        "print(f\"Loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
        "\n",
        "# Step 1: Map variable names to match our previous analysis\n",
        "# ------------------------------------------------------------------\n",
        "print(\"Mapping variable names...\")\n",
        "\n",
        "# Create dictionary to map new column names to the ones we used before\n",
        "var_mapping = {\n",
        "    'ResponseId': 'Response ID',                      # ID column\n",
        "    'male_binary': 'Gender',                          # Demographics\n",
        "    'poor_physhealth_binary': 'poor_phys',            # Health status\n",
        "    'poorMH': 'poor_mental',\n",
        "    'poor_QOL_binary': 'poor_qol',\n",
        "    'sought_care_recently_binary': 'sought_care_recently',  # Outcomes\n",
        "    'pct_times_got_care': 'pct_times_get_Care',\n",
        "    'mean_satisfied_w_care': 'mean_satisfaction'\n",
        "}\n",
        "\n",
        "# Create new columns with the old names for consistency\n",
        "for new_col, old_col in var_mapping.items():\n",
        "    if new_col in df.columns:\n",
        "        df[old_col] = df[new_col]\n",
        "    else:\n",
        "        print(f\"Warning: {new_col} not found in the dataset\")\n",
        "\n",
        "# Special case: Gender was 1=Male, 0=Female in the original dataset\n",
        "# In the new dataset it's male_binary (1=Male, 0=Female)\n",
        "# Since we want 1=Female, 0=Male to match the previous analysis:\n",
        "if 'Gender' in df.columns:\n",
        "    df['Gender'] = 1 - df['Gender']  # Convert male_binary to female_binary\n",
        "\n",
        "# Step 2: Create the intermediate variables needed for our composite measures\n",
        "# ------------------------------------------------------------------\n",
        "print(\"Creating intermediate variables...\")\n",
        "\n",
        "# Create age groups from age column\n",
        "df['age_group'] = pd.cut(df['age'],\n",
        "                         bins=[0, 44, 64, float('inf')],\n",
        "                         labels=['18-44', '45-64', '65+'])\n",
        "\n",
        "# Create health issues count\n",
        "health_vars = ['poor_phys', 'poor_mental', 'poor_qol', 'chronic_cond_binary']\n",
        "if all(var in df.columns for var in health_vars):\n",
        "    df['health_issues_count'] = df[health_vars].sum(axis=1)\n",
        "    print(\"Created health_issues_count\")\n",
        "else:\n",
        "    missing = [var for var in health_vars if var not in df.columns]\n",
        "    print(f\"Cannot create health_issues_count - missing: {missing}\")\n",
        "\n",
        "# Create social determinants of health vulnerability score\n",
        "sdoh_vars = ['food_insecure_binary', 'house_insecure_binary',\n",
        "             'transport_insecure_binary', 'income_insecure_binary']\n",
        "if all(var in df.columns for var in sdoh_vars):\n",
        "    df['sdoh_vulnerability_score'] = df[sdoh_vars].sum(axis=1)\n",
        "    print(\"Created sdoh_vulnerability_score\")\n",
        "else:\n",
        "    missing = [var for var in sdoh_vars if var not in df.columns]\n",
        "    print(f\"Cannot create sdoh_vulnerability_score - missing: {missing}\")\n",
        "\n",
        "# Create facilities within 30 minutes measure\n",
        "# Note: The new dataset has specific columns for each facility type\n",
        "if all(col in df.columns for col in ['prim_care_less30min', 'er_care_less30min']):\n",
        "    # Count how many facility types are within 30 minutes\n",
        "    facility_cols = [col for col in df.columns if col.endswith('_less30min')]\n",
        "    df['facilities_within_30min'] = df[facility_cols].sum(axis=1)\n",
        "    print(f\"Created facilities_within_30min from {len(facility_cols)} facility columns\")\n",
        "else:\n",
        "    # Alternative: Use original Q2.19 columns to calculate if available\n",
        "    proximity_cols = ['Q2.19_1', 'Q2.19_3', 'Q2.19_4', 'Q2.19_5']\n",
        "    if all(col in df.columns for col in proximity_cols):\n",
        "        df['facilities_within_30min'] = df[proximity_cols].apply(\n",
        "            lambda x: sum([(1 if pd.notnull(val) and val in [1, 2] else 0) for val in x]), axis=1)\n",
        "        print(\"Created facilities_within_30min from Q2.19 columns\")\n",
        "    else:\n",
        "        print(\"Cannot create facilities_within_30min - missing required columns\")\n",
        "\n",
        "# Step 3: Create the exact variables needed for our focused dataset\n",
        "# ------------------------------------------------------------------\n",
        "print(\"Creating focused dataset variables...\")\n",
        "\n",
        "# 1. Create high_health_need indicator\n",
        "if 'health_issues_count' in df.columns:\n",
        "    df['high_health_need'] = (df['health_issues_count'] >= 2).astype(int)\n",
        "    # Create healthcare needs binary\n",
        "    df['high_needs_binary'] = ((df['high_health_need'] + df['chronic_cond_binary'] >= 1)\n",
        "                              .astype(int))\n",
        "    print(\"Created high_needs_binary\")\n",
        "else:\n",
        "    print(\"Cannot create high_needs_binary - missing health_issues_count\")\n",
        "\n",
        "# 2. Create high_social_vulnerability indicator\n",
        "if 'sdoh_vulnerability_score' in df.columns:\n",
        "    df['high_social_vulnerability'] = (df['sdoh_vulnerability_score'] >= 2).astype(int)\n",
        "    print(\"Created high_social_vulnerability\")\n",
        "else:\n",
        "    print(\"Cannot create high_social_vulnerability - missing sdoh_vulnerability_score\")\n",
        "\n",
        "# 3. Create low_geographic_access indicator\n",
        "if 'facilities_within_30min' in df.columns:\n",
        "    df['low_geographic_access'] = (df['facilities_within_30min'] <= 2).astype(int)\n",
        "    print(\"Created low_geographic_access\")\n",
        "else:\n",
        "    print(\"Cannot create low_geographic_access - missing facilities_within_30min\")\n",
        "\n",
        "# 4. Create healthcare barriers binary (from high_social_vulnerability, low_geographic_access, self_insured_binary)\n",
        "if all(var in df.columns for var in ['high_social_vulnerability', 'low_geographic_access', 'self_insured_binary']):\n",
        "    df['healthcare_barriers'] = (\n",
        "        df['high_social_vulnerability'] +\n",
        "        df['low_geographic_access'] +\n",
        "        (1 - df['self_insured_binary'])  # Reverse coding: 1 = not insured\n",
        "    )\n",
        "    df['high_barriers_binary'] = (df['healthcare_barriers'] >= 2).astype(int)\n",
        "    print(\"Created high_barriers_binary\")\n",
        "else:\n",
        "    print(\"Cannot create high_barriers_binary - missing required variables\")\n",
        "\n",
        "# 5. Create demographic group indicators\n",
        "if all(var in df.columns for var in ['age_group', 'college_ed_binary']):\n",
        "    # Create demographic group\n",
        "    conditions = [\n",
        "        (df['age_group'] == '18-44') & (df['college_ed_binary'] == 1),\n",
        "        (df['age_group'] == '18-44') & (df['college_ed_binary'] == 0),\n",
        "        df['age_group'].isin(['45-64', '65+'])\n",
        "    ]\n",
        "    choices = ['young_educated', 'young_uneducated', 'middle_older']\n",
        "    df['demographic_group'] = np.select(conditions, choices, default='unknown')\n",
        "\n",
        "    # Create boolean flags for each demographic group\n",
        "    df['demo_young_educated'] = (df['demographic_group'] == 'young_educated')\n",
        "    df['demo_young_uneducated'] = (df['demographic_group'] == 'young_uneducated')\n",
        "    df['demo_middle_older'] = (df['demographic_group'] == 'middle_older')\n",
        "    print(\"Created demographic group indicators\")\n",
        "else:\n",
        "    print(\"Cannot create demographic groups - missing required variables\")\n",
        "\n",
        "# Convert percentage string to float for pct_times_get_Care if needed\n",
        "if 'pct_times_get_Care' in df.columns and df['pct_times_get_Care'].dtype == 'object':\n",
        "    df['pct_times_get_Care'] = df['pct_times_get_Care'].str.rstrip('%').astype('float') / 100\n",
        "    print(\"Converted pct_times_get_Care to float\")\n",
        "\n",
        "# Step 4: Create the exact focused dataset with matching structure\n",
        "# ------------------------------------------------------------------\n",
        "print(\"Creating final focused dataset...\")\n",
        "\n",
        "# Select the exact columns needed for the focused dataset\n",
        "focused_columns = [\n",
        "    'Response ID',                 # Identifier\n",
        "    'high_barriers_binary',        # Barriers\n",
        "    'high_needs_binary',           # Health needs\n",
        "    'demo_young_educated',         # Demographics\n",
        "    'demo_young_uneducated',\n",
        "    'demo_middle_older',\n",
        "    'sought_care_recently',        # Outcomes\n",
        "    'pct_times_get_Care',\n",
        "    'mean_satisfaction'\n",
        "]\n",
        "\n",
        "# Check which columns we have\n",
        "available_columns = [col for col in focused_columns if col in df.columns]\n",
        "missing_columns = [col for col in focused_columns if col not in df.columns]\n",
        "if missing_columns:\n",
        "    print(f\"Warning: Missing columns in final dataset: {missing_columns}\")\n",
        "\n",
        "# Create the focused dataset\n",
        "focused_df = df[available_columns].copy()\n",
        "\n",
        "# Ensure boolean columns are actually boolean type\n",
        "for col in ['demo_young_educated', 'demo_young_uneducated', 'demo_middle_older']:\n",
        "    if col in focused_df.columns:\n",
        "        focused_df[col] = focused_df[col].astype('bool')\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = focused_df.isnull().sum()\n",
        "print(\"\\nMissing values in focused dataset:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Create a version without missing values\n",
        "focused_df_complete = focused_df.dropna()\n",
        "print(f\"\\nFocused dataset: {focused_df.shape[0]} rows before removing missing values\")\n",
        "print(f\"Focused dataset: {focused_df_complete.shape[0]} rows after removing missing values\")\n",
        "\n",
        "# Save the datasets\n",
        "focused_df.to_csv('focused_dataset_new_all.csv', index=False)\n",
        "focused_df_complete.to_csv('focused_dataset_new.csv', index=False)\n",
        "\n",
        "print(\"\\nFocused dataset created and saved as 'focused_dataset_new.csv'\")\n",
        "print(\"Sample of the focused dataset:\")\n",
        "print(focused_df.head())\n",
        "\n",
        "# Compare data types with original focused dataset\n",
        "print(\"\\nColumn data types in new focused dataset:\")\n",
        "print(focused_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/189_dataset - NUMERIC_HealthIssuesRuralTX_Net.csv')\n",
        "\n",
        "# Create age groups from Age column\n",
        "df['age_group'] = pd.cut(pd.to_numeric(df['Age'], errors='coerce'),\n",
        "                         bins=[0, 44, 64, float('inf')],\n",
        "                         labels=['18-44', '45-64', '65+'])\n",
        "\n",
        "# Create health issues count\n",
        "df['health_issues_count'] = df['poor_phys'] + df['poor_mental'] + df['poor_qol'] + df['chronic_cond_binary']\n",
        "\n",
        "# Create social determinants of health vulnerability score\n",
        "df['sdoh_vulnerability_score'] = (df['food_insecure_binary'] + df['house_insecure_binary'] +\n",
        "                                 df['transport_insecure_binary'] + df['income_insecure_binary'])\n",
        "\n",
        "# Create healthcare proximity measures\n",
        "# Count facilities within 30 minutes (assuming 1 and 2 are the codes for \"within 30 minutes\")\n",
        "proximity_time_cols = ['Q2.19_1', 'Q2.19_2', 'Q2.19_3', 'Q2.19_4', 'Q2.19_5']\n",
        "df['facilities_within_30min'] = df[proximity_time_cols].apply(\n",
        "    lambda x: sum([(1 if pd.notnull(val) and val in [1, 2] else 0) for val in x]), axis=1)\n",
        "\n",
        "# Count facilities within 10 miles (assuming 1 and 2 are the codes for \"within 10 miles\")\n",
        "proximity_distance_cols = ['Q2.20_1', 'Q2.20_2', 'Q2.20_3', 'Q2.20_4', 'Q2.20_5']\n",
        "df['facilities_within_10miles'] = df[proximity_distance_cols].apply(\n",
        "    lambda x: sum([(1 if pd.notnull(val) and val in [1, 2] else 0) for val in x]), axis=1)\n",
        "\n",
        "# Create binary indicators for specific facilities being nearby\n",
        "df['primary_care_nearby'] = df['Q2.19_1'].apply(lambda x: 1 if pd.notnull(x) and x in [1, 2] else 0)\n",
        "df['urgent_care_nearby'] = df['Q2.19_2'].apply(lambda x: 1 if pd.notnull(x) and x in [1, 2] else 0)\n",
        "df['er_nearby'] = df['Q2.19_5'].apply(lambda x: 1 if pd.notnull(x) and x in [1, 2] else 0)\n",
        "\n",
        "# Create incorrect care binary indicator from Q2.22\n",
        "df['incorrect_care_binary'] = df['Q2.22'].apply(lambda x: 1 if pd.notnull(x) and x == 1 else 0)\n",
        "\n",
        "# Create the final dataset for clustering with selected variables\n",
        "cluster_df = df[['Response ID', 'age_group', 'Gender', 'college_ed_binary', 'employed_binary',\n",
        "                 'chronic_cond_binary', 'pregnant_binary', 'poor_phys', 'poor_mental', 'poor_qol',\n",
        "                 'health_issues_count', 'food_insecure_binary', 'house_insecure_binary',\n",
        "                 'transport_insecure_binary', 'income_insecure_binary', 'sdoh_vulnerability_score',\n",
        "                 'self_insured_binary', 'difficult_afford_health', 'facilities_within_30min',\n",
        "                 'facilities_within_10miles', 'primary_care_nearby', 'urgent_care_nearby', 'er_nearby',\n",
        "                 'difficulty_coping_binary', 'sought_care_recently', 'pct_times_get_Care',\n",
        "                 'mean_satisfaction', 'incorrect_care_binary']].copy()\n",
        "\n",
        "# Convert percentage string to float if needed\n",
        "if 'pct_times_get_Care' in cluster_df.columns and cluster_df['pct_times_get_Care'].dtype == 'object':\n",
        "    cluster_df['pct_times_get_Care'] = cluster_df['pct_times_get_Care'].str.rstrip('%').astype('float') / 100\n",
        "\n",
        "# Handle missing values for branching logic questions without removing records\n",
        "# For questions where NA means \"not applicable\" due to branching logic, fill with appropriate values\n",
        "\n",
        "# For pregnant_binary, NA likely means not applicable (male respondent or didn't answer)\n",
        "if 'pregnant_binary' in cluster_df.columns:\n",
        "    cluster_df['pregnant_binary'] = cluster_df['pregnant_binary'].fillna(0)  # Not applicable = 0\n",
        "\n",
        "# For pct_times_get_Care, if NA, it might mean they never needed care\n",
        "# Rather than drop these records, we can set to a value that makes sense (e.g., 1.0 for 100% since they never failed)\n",
        "if 'pct_times_get_Care' in cluster_df.columns:\n",
        "    cluster_df['pct_times_get_Care'] = cluster_df['pct_times_get_Care'].fillna(1.0)\n",
        "\n",
        "# For mean_satisfaction, if NA, might mean they never sought care\n",
        "# Fill with the middle/neutral value of the scale (assuming it's a 1-5 scale)\n",
        "if 'mean_satisfaction' in cluster_df.columns:\n",
        "    cluster_df['mean_satisfaction'] = cluster_df['mean_satisfaction'].fillna(3.0)\n",
        "\n",
        "# For incorrect_care_binary, NA might mean they haven't sought care\n",
        "if 'incorrect_care_binary' in cluster_df.columns:\n",
        "    cluster_df['incorrect_care_binary'] = cluster_df['incorrect_care_binary'].fillna(0)\n",
        "\n",
        "# Check that we have all 159 records\n",
        "print(f\"Number of records in final dataset: {len(cluster_df)}\")\n",
        "\n",
        "# Create a standardized version for clustering\n",
        "cluster_data_standardized = cluster_df.copy()\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "cluster_data_standardized = pd.get_dummies(cluster_data_standardized,\n",
        "                                          columns=['age_group'],\n",
        "                                          drop_first=False)\n",
        "\n",
        "# Standardize continuous variables\n",
        "scaler = StandardScaler()\n",
        "continuous_cols_to_scale = ['health_issues_count', 'sdoh_vulnerability_score',\n",
        "                            'facilities_within_30min', 'facilities_within_10miles',\n",
        "                            'pct_times_get_Care', 'mean_satisfaction']\n",
        "\n",
        "# Create standardized versions with suffix\n",
        "for col in continuous_cols_to_scale:\n",
        "    if col in cluster_data_standardized.columns:\n",
        "        new_col_name = f\"{col}_scaled\"\n",
        "        cluster_data_standardized[new_col_name] = scaler.fit_transform(\n",
        "            cluster_data_standardized[[col]])\n",
        "\n",
        "# Save both versions\n",
        "cluster_df.to_csv('cluster_data_.csv', index=False)\n",
        "cluster_data_standardized.to_csv('cluster_data_standardized.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the prepared dataset\n",
        "print(\"\\nOriginal cluster data (first 5 rows):\")\n",
        "print(cluster_df.head())"
      ],
      "metadata": {
        "id": "SbaZ3PNJjSkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}